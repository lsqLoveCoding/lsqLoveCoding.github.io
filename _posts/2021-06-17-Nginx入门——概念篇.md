---
layout:     post                    # 使用的布局（不需要改）
title:      Nginx入门——概念篇            # 标题 
subtitle:    整理自公众号【好好学java】
date:       2021-06-17              # 时间
author:     LSQ                      # 作者
# header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Nginx
---

# Nginx应用核心概念
&emsp;&emsp;代理是在服务器和客户端之间假设的一层服务器，代理将接收客户端的请求并将它转发给服务器，然后将服务端的响应转发给客户端。  
&emsp;&emsp;不管是正向代理还是反向代理，实现的都是上面的功能。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617103108997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
## 正向代理
&emsp;&emsp;**正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。**  

&emsp;&emsp;正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。  
&emsp;&emsp;正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。  
## 反向代理
&emsp;&emsp;**反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。**
&emsp;&emsp;反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。  
&emsp;&emsp;反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。  
&emsp;&emsp;反向代理的优势：  

 - 隐藏真实服务器； 
 - 负载均衡便于横向扩充后端动态服务； 
 - 动静分离，提升系统健壮性；

&emsp;&emsp;那么“动静分离”是什么？负载均衡又是什么？  
## 动静分离
&emsp;&emsp;动静分离是指在 web 服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提示整个服务的访问性和可维护性。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617104135901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;一般来说，都需要将动态资源和静态资源分开，由于 Nginx 的高并发和静态资源缓存等特性，经常将静态资源部署在 Nginx 上。如果请求的是静态资源，直接到静态资源目录获取资源，如果是动态资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。  
&emsp;&emsp;使用前后端分离后，可以很大程度提升静态资源的访问速度，即使动态服务不可用，静态资源的访问也不会受到影响。  
## 负载均衡
&emsp;&emsp;一般情况下，客户端发送多个请求到服务器，服务器处理请求，其中一部分可能要操作一些资源比如数据库、静态资源等，服务器处理完毕后，再将结果返回给客户端。
&emsp;&emsp;这种模式对于早期的系统来说，功能要求不复杂，且并发请求相对较少的情况下还能胜任，成本也低。随着信息数量不断增长，访问量和数据量飞速增长，以及系统业务复杂度持续增加，这种做法已无法满足要求，并发量特别大时，服务器容易崩。
&emsp;&emsp;很明显这是由于服务器性能的瓶颈造成的问题，除了堆机器之外，最重要的做法就是负载均衡。  
&emsp;&emsp;请求爆发式增长的情况下，单个机器性能再强劲也无法满足要求了，这个时候集群的概念产生了，单个服务器解决不了的问题，可以使用多个服务器，然后将请求分发到各个服务器上，将负载分发到不同的服务器，这就是负载均衡，核心是「分摊压力」。Nginx 实现负载均衡，一般来说指的是将请求转发给服务器集群。  
&emsp;&emsp;举个具体的例子，晚高峰乘坐地铁的时候，入站口经常会有地铁工作人员大喇叭“请走 B 口， B 口人少车空....”，这个工作人员的作用就是负载均衡。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617125530291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;Nginx 实现负载均衡的策略：  

 - 轮询策略：默认情况下采用的策略，将所有客户端请求轮询分配给服务端。这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。
 - 最小连接数策略：将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求。
 - 最快响应时间策略：优先分配给响应时间最短的服务器。 
 - 客户端 ip 绑定策略：来自同一个 ip的请求永远只分配一台服务器，有效解决了动态网页存在的 session 共享问题。

## Nginx实战配置
&emsp;&emsp;在配置反向代理和负载均衡等等功能之前，有两个核心模块是我们必须要掌握的，这两个模块应该说是 Nginx 应用配置中的核心，它们分别是：upstream 、proxy_pass 。  
### upstream
&emsp;&emsp;用于定义上游服务器（指的就是后台提供的应用服务器）的相关信息。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617125733539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)

```xml
语法：upstream name {
 ...
}

上下文：http

示例：
upstream back_end_server{
  server 192.168.100.33:8081
}
```
&emsp;&emsp;在 upstream 内可使用的指令：  

 - server 定义上游服务器地址； 
 - zone 定义共享内存，用于跨 worker 子进程； 
 - keepalive 对上游服务启用长连接；
 - keepalive_requests 一个长连接最多请求 HTTP 的个数
 - keepalive_timeout 空闲情形下，一个长连接的超时时长； 
 - hash 哈希负载均衡算法； 
 - ip_hash 依据 IP 进行哈希计算的负载均衡算法；
 - least_conn 最少连接数负载均衡算法； 
 - least_time 最短响应时间负载均衡算法； 
 - random 随机负载均衡算法；

### server
&emsp;&emsp;定义上游服务器地址。    

```xml
语法：server address [parameters]

上下文：upstream
```
&emsp;&emsp;parameters 可选值：  

 - weight=number 权重值，默认为1； 
 - max_conns=number 上游服务器的最大并发连接数；
 - fail_timeout=time 服务器不可用的判定时间； 
 - max_fails=numer 服务器不可用的检查次数； 
 - backup备份服务器，仅当其他服务器都不可用时才会启用； 
 - down 标记服务器长期不可用，离线维护；

### keepalive
&emsp;&emsp;限制每个 worker 子进程与上游服务器空闲长连接的最大数量。  

```xml
keepalive connections;

上下文：upstream

示例：keepalive 16;
```
### keepalive_requests
&emsp;&emsp;单个长连接可以处理的最多 HTTP 请求个数。  

```xml
语法：keepalive_requests number;

默认值：keepalive_requests 100;

上下文：upstream
```
### keepalive_timeout
&emsp;&emsp;空闲长连接的最长保持时间。  

```xml
语法：keepalive_timeout time;

默认值：keepalive_timeout 60s;

上下文：upstream
```
### 配置实例

```xml
upstream back_end{
 server 127.0.0.1:8081 weight=3 max_conns=1000 fail_timeout=10s max_fails=2;
  keepalive 32;
  keepalive_requests 50;
  keepalive_timeout 30s;
}
```
### proxy_pass
&emsp;&emsp;用于配置代理服务器。  

```xml
语法：proxy_pass URL;

上下文：location、if、limit_except

示例：
proxy_pass http://127.0.0.1:8081
proxy_pass http://127.0.0.1:8081/proxy
```
&emsp;&emsp;URL 参数原则  
 - URL 必须以 http 或 https 开头； 
 - URL 中可以携带变量； 
 - URL 中是否带 URI ，会直接影响发往上游请求的 URL；

&emsp;&emsp;接下来让我们来看看两种常见的 URL 用法：  

 - proxy_pass http://192.168.100.33:8081 
 - proxy_passhttp://192.168.100.33:8081/
 
&emsp;&emsp;这两种用法的区别就是带 / 和不带 / ，在配置代理时它们的区别可大了：  
 - 不带 / 意味着 Nginx 不会修改用户 URL ，而是直接透传给上游的应用服务器； 
 - 带 / 意味着 Nginx 会修改用户 URL，修改方法是将 location 后的 URL 从用户 URL 中删除；

&emsp;&emsp;不带 / 的用法：  

```xml
location /bbs/{
  proxy_pass http://127.0.0.1:8080;
}
```
&emsp;&emsp;分析：  

 - 用户请求 URL ：/bbs/abc/test.html 
 - 请求到达 Nginx 的 URL ：/bbs/abc/test.html
 - 请求到达上游应用服务器的 URL ：/bbs/abc/test.html

&emsp;&emsp;带 / 的用法：  

```xml
location /bbs/{
  proxy_pass http://127.0.0.1:8080/;
}
```
&emsp;&emsp;分析：  

 - 用户请求 URL ：/bbs/abc/test.html 
 - 请求到达 Nginx 的 URL ：/bbs/abc/test.html
 - 请求到达上游应用服务器的 URL ：/abc/test.html

&emsp;&emsp;并没有拼接上 /bbs ，这点和 root 与 alias 之间的区别是保持一致的。  
## 配置反向代理
&emsp;&emsp;这里为了演示更加接近实际，作者准备了两台云服务器，它们的公网 IP 分别是：121.42.11.34 与 121.5.180.193 。  
&emsp;&emsp;我们把 121.42.11.34 服务器作为上游服务器，做如下配置：  

```xml
# /etc/nginx/conf.d/proxy.conf
server{
  listen 8080;
  server_name localhost;
  
  location /proxy/ {
    root /usr/share/nginx/html/proxy;
    index index.html;
  }
}

# /usr/share/nginx/html/proxy/index.html
<h1> 121.42.11.34 proxy html </h1>
```
&emsp;&emsp;配置完成后重启 Nginx 服务器 nginx \-s reload 。  
&emsp;&emsp;把 121.5.180.193 服务器作为代理服务器，做如下配置：  

```xml
# /etc/nginx/conf.d/proxy.conf
upstream back_end {
  server 121.42.11.34:8080 weight=2 max_conns=1000 fail_timeout=10s max_fails=3;
  keepalive 32;
  keepalive_requests 80;
  keepalive_timeout 20s;
}

server {
  listen 80;
  server_name proxy.lion.club;
  location /proxy {
   proxy_pass http://back_end/proxy;
  }
}
```
&emsp;&emsp;本地机器要访问 proxy.lion.club 域名，因此需要配置本地 hosts ，通过命令：vim /etc/hosts 进入配置文件，添加如下内容：  

```xml
121.5.180.193 proxy.lion.club
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617132800274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;分析：  
&emsp;&emsp;当访问 proxy.lion.club/proxy 时通过 upstream 的配置找到 121.42.11.34:8080 ；  
&emsp;&emsp;因此访问地址变为 http://121.42.11.34:8080/proxy ；  
&emsp;&emsp;连接到 121.42.11.34 服务器，找到 8080 端口提供的 server ；  
&emsp;&emsp;通过 server 找到 /usr/share/nginx/html/proxy/index.html 资源，最终展示出来。  
## 配置负载均衡
&emsp;&emsp;配置负载均衡主要是要使用 upstream 指令。  
&emsp;&emsp;我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ /etc/nginx/conf.d/balance.conf ）：  

```xml
server{
  listen 8020;
  location / {
   return 200 'return 8020 \n';
  }
}

server{
  listen 8030;
  location / {
   return 200 'return 8030 \n';
  }
}

server{
  listen 8040;
  location / {
   return 200 'return 8040 \n';
  }
}
```
&emsp;&emsp;配置完成后：  
1. nginx -t 检测配置是否正确；
2. nginx -s reload 重启 Nginx 服务器；
3. 执行 ss -nlt 命令查看端口是否被占用，从而判断 Nginx 服务是否正确启动。

&emsp;&emsp;把 121.5.180.193 服务器作为代理服务器，做如下配置（ /etc/nginx/conf.d/balance.conf ）：  

```xml
upstream demo_server {
  server 121.42.11.34:8020;
  server 121.42.11.34:8030;
  server 121.42.11.34:8040;
}

server {
  listen 80;
  server_name balance.lion.club;
  
  location /balance/ {
   proxy_pass http://demo_server;
  }
}
```
&emsp;&emsp;配置完成后重启 Nginx 服务器。并且在需要访问的客户端配置好 ip 和域名的映射关系。  

```xml
# /etc/hosts

121.5.180.193 balance.lion.club
```
&emsp;&emsp;在客户端机器执行 curl http://balance.lion.club/balance/ 命令：  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617133653908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;不难看出，负载均衡的配置已经生效了，每次给我们分发的上游服务器都不一样。就是通过简单的轮询策略进行上游服务器分发。  
&emsp;&emsp;接下来，我们再来了解下 Nginx 的其它分发策略。  
### hash算法
&emsp;&emsp;通过制定关键字作为 hash key ，基于 hash 算法映射到特定的上游服务器中。关键字可以包含有变量、字符串。  

```xml
upstream demo_server {
  hash $request_uri;
  server 121.42.11.34:8020;
  server 121.42.11.34:8030;
  server 121.42.11.34:8040;
}

server {
  listen 80;
  server_name balance.lion.club;
  
  location /balance/ {
   proxy_pass http://demo_server;
  }
}
```
&emsp;&emsp;hash $request_uri 表示使用 request_uri 变量作为 hash 的 key 值，只要访问的 URI 保持不变，就会一直分发给同一台服务器。  
### ip_hash
&emsp;&emsp;根据客户端的请求 ip 进行判断，只要 ip 地址不变就永远分配到同一台主机。它可以有效解决后台服务器 session 保持的问题。  

```xml
upstream demo_server {
  ip_hash;
  server 121.42.11.34:8020;
  server 121.42.11.34:8030;
  server 121.42.11.34:8040;
}

server {
  listen 80;
  server_name balance.lion.club;
  
  location /balance/ {
   proxy_pass http://demo_server;
  }
}
```
### 最少连接数算法
&emsp;&emsp;各个 worker 子进程通过读取共享内存的数据，来获取后端服务器的信息。来挑选一台当前已建立连接数最少的服务器进行分配请求。  

```xml
语法：least_conn;

上下文：upstream;

```
&emsp;&emsp;示例：  

```xml
upstream demo_server {
  zone test 10M; # zone可以设置共享内存空间的名字和大小
  least_conn;
  server 121.42.11.34:8020;
  server 121.42.11.34:8030;
  server 121.42.11.34:8040;
}

server {
  listen 80;
  server_name balance.lion.club;
  
  location /balance/ {
   proxy_pass http://demo_server;
  }
}
```
&emsp;&emsp;最后你会发现，负载均衡的配置其实一点都不复杂。  
## 配置缓存
&emsp;&emsp;缓存可以非常有效的提升性能，因此不论是客户端（浏览器），还是代理服务器（ Nginx ），乃至上游服务器都多少会涉及到缓存。可见缓存在每个环节都是非常重要的。下面让我们来学习 Nginx 中如何设置缓存策略。  
### proxy_cache
&emsp;&emsp;存储一些之前被访问过、而且可能将要被再次访问的资源，使用户可以直接从代理服务器获得，从而减少上游服务器的压力，加快整个访问速度。  

```xml
语法：proxy_cache zone | off ; # zone 是共享内存的名称

默认值：proxy_cache off;

上下文：http、server、location
```
### proxy_cache_path
&emsp;&emsp;设置缓存文件的存放路径。  

```xml
语法：proxy_cache_path path [level=levels] ...可选参数省略，下面会详细列举

默认值：proxy_cache_path off

上下文：http
```
&emsp;&emsp;参数含义：  

 - path 缓存文件的存放路径； 
 - level path 的目录层级； 
 - keys_zone 设置共享内存； 
 - inactive在指定时间内没有被访问，缓存会被清理，默认10分钟；

### proxy_cache_key
&emsp;&emsp;设置缓存文件的 key 。  

```xml
语法：proxy_cache_key

默认值：proxy_cache_key $scheme$proxy_host$request_uri;

上下文：http、server、location
```
### proxy_cache_valid
&emsp;&emsp;配置什么状态码可以被缓存，以及缓存时长。  

```xml
语法：proxy_cache_valid [code...] time;

上下文：http、server、location

配置示例：proxy_cache_valid 200 304 2m;; # 说明对于状态为200和304的缓存文件的缓存时间是2分钟
```
### proxy_no_cache
&emsp;&emsp;定义相应保存到缓存的条件，如果字符串参数的至少一个值不为空且不等于“ 0”，则将不保存该响应到缓存。  

```xml
语法：proxy_no_cache string;

上下文：http、server、location

示例：proxy_no_cache $http_pragma    $http_authorization;
```
### proxy_cache_bypass
&emsp;&emsp;定义条件，在该条件下将不会从缓存中获取响应。  

```xml
语法：proxy_cache_bypass string;

上下文：http、server、location

示例：proxy_cache_bypass $http_pragma    $http_authorization;
```
### upstream_cache_status 变量
&emsp;&emsp;它存储了缓存是否命中的信息，会设置在响应头信息中，在调试中非常有用。  

```xml
MISS: 未命中缓存
HIT：命中缓存
EXPIRED: 缓存过期
STALE: 命中了陈旧缓存
REVALIDDATED: Nginx验证陈旧缓存依然有效
UPDATING: 内容陈旧，但正在更新
BYPASS: X响应从原始服务器获取
```
### 配置实例
&emsp;&emsp;我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ /etc/nginx/conf.d/cache.conf ）：  

```xml
server {
  listen 1010;
  root /usr/share/nginx/html/1010;
  location / {
   index index.html;
  }
}

server {
  listen 1020;
  root /usr/share/nginx/html/1020;
  location / {
   index index.html;
  }
}
```
&emsp;&emsp;把 121.5.180.193 服务器作为代理服务器，做如下配置（ /etc/nginx/conf.d/cache.conf ）：  

```xml
proxy_cache_path /etc/nginx/cache_temp levels=2:2 keys_zone=cache_zone:30m max_size=2g inactive=60m use_temp_path=off;

upstream cache_server{
  server 121.42.11.34:1010;
  server 121.42.11.34:1020;
}

server {
  listen 80;
  server_name cache.lion.club;
  location / {
    proxy_cache cache_zone; # 设置缓存内存，上面配置中已经定义好的
    proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟
    proxy_cache_key $request_uri; # 缓存文件的key为请求的URI
    add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端
    proxy_pass http://cache_server; # 代理转发
  }
}
```
&emsp;&emsp;缓存就是这样配置，我们可以在 /etc/nginx/cache_temp 路径下找到相应的缓存文件。  
&emsp;&emsp;**对于一些实时性要求非常高的页面或数据来说，就不应该去设置缓存，下面来看看如何配置不缓存的内容。**  

```xml
...

server {
  listen 80;
  server_name cache.lion.club;
  # URI 中后缀为 .txt 或 .text 的设置变量值为 "no cache"
  if ($request_uri ~ \.(txt|text)$) {
   set $cache_name "no cache"
  }
  
  location / {
    proxy_no_cache $cache_name; # 判断该变量是否有值，如果有值则不进行缓存，如果没有值则进行缓存
    proxy_cache cache_zone; # 设置缓存内存
    proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟
    proxy_cache_key $request_uri; # 缓存文件的key为请求的URI
    add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端
    proxy_pass http://cache_server; # 代理转发
  }
}
```
## HTTPS
&emsp;&emsp;在学习如何配置 HTTPS 之前，我们先来简单回顾下 HTTPS 的工作流程是怎么样的？它是如何进行加密保证安全的？  
### HTTPS 工作流程
1. 客户端（浏览器）访问 https://www.baidu.com 百度网站；
2. 百度服务器返回 HTTPS 使用的 CA 证书；
3. 浏览器验证 CA 证书是否为合法证书；
4. 验证通过，证书合法，生成一串随机数并使用公钥（证书中提供的）进行加密；
5. 发送公钥加密后的随机数给百度服务器；
6. 百度服务器拿到密文，通过私钥进行解密，获取到随机数（公钥加密，私钥解密，反之也可以）；
7. 百度服务器把要发送给浏览器的内容，使用随机数进行加密后传输给浏览器；
8. 此时浏览器可以使用随机数进行解密，获取到服务器的真实传输内容；


&emsp;&emsp;这就是 HTTPS 的基本运作原理，使用对称加密和非对称机密配合使用，保证传输内容的安全性。  
### 配置证书
&emsp;&emsp;下载证书的压缩文件，里面有个 Nginx 文件夹，把 xxx.crt 和 xxx.key 文件拷贝到服务器目录，再进行如下配置：  

```xml
server {
  listen 443 ssl http2 default_server; # SSL 访问端口号为 443
  server_name lion.club; # 填写绑定证书的域名(我这里是随便写的)
  ssl_certificate /etc/nginx/https/lion.club_bundle.crt; # 证书地址
  ssl_certificate_key /etc/nginx/https/lion.club.key; # 私钥地址
  ssl_session_timeout 10m;
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 支持ssl协议版本，默认为后三个，主流版本是[TLSv1.2]
 
  location / {
    root         /usr/share/nginx/html;
    index        index.html index.htm;
  }
}
```
&emsp;&emsp;如此配置后就能正常访问 HTTPS 版的网站了。  
## 配置跨域 CORS
&emsp;&emsp;先简单回顾下跨域究竟是怎么回事。  
### 跨域的定义
&emsp;&emsp;同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。通常不允许不同源间的读操作。  
### 同源的定义
&emsp;&emsp;如果两个页面的协议，端口（如果有指定）和域名都相同，则两个页面具有相同的源。  
&emsp;&emsp;下面给出了与URLhttp://store.company.com/dir/page.html 的源进行对比的示例:    

```xml
http://store.company.com/dir2/other.html 同源
https://store.company.com/secure.html 不同源，协议不同
http://store.company.com:81/dir/etc.html 不同源，端口不同
http://news.company.com/dir/other.html 不同源，主机不同
```
&emsp;&emsp;不同源会有如下限制：  
 - Web 数据层面，同源策略限制了不同源的站点读取当前站点的 Cookie 、 IndexDB 、 LocalStorage 等数据。
 - DOM 层面，同源策略限制了来自不同源的 JavaScript 脚本对当前 DOM 对象读和写的操作。 
 - 网络层面，同源策略限制了通过XMLHttpRequest 等方式将站点的数据发送给不同源的站点。

## Nginx 解决跨域的原理
&emsp;&emsp;例如：  

 - 前端 server 的域名为：fe.server.com 
 - 后端服务的域名为：dev.server.com

&emsp;&emsp;现在我在 fe.server.com 对 dev.server.com 发起请求一定会出现跨域。  
&emsp;&emsp;现在我们只需要启动一个 Nginx 服务器，将 server_name 设置为 fe.server.com 然后设置相应的 location 以拦截前端需要跨域的请求，最后将请求代理回 dev.server.com 。如下面的配置：  

```xml
server {
 listen      80;
 server_name  fe.server.com;
 location / {
  proxy_pass dev.server.com;
 }
}
```
&emsp;&emsp;这样可以完美绕过浏览器的同源策略：fe.server.com 访问 Nginx 的 fe.server.com 属于同源访问，而 Nginx 对服务端转发的请求不会触发浏览器的同源策略。  
## 配置开启 gzip 压缩
&emsp;&emsp;GZIP 是规定的三种标准 HTTP 压缩格式之一。目前绝大多数的网站都在使用 GZIP 传输 HTML 、CSS 、 JavaScript 等资源文件。  
&emsp;&emsp;对于文本文件， GZiP 的效果非常明显，开启后传输所需流量大约会降至 1/4~1/3 。  
&emsp;&emsp;并不是每个浏览器都支持 gzip 的，如何知道客户端是否支持 gzip 呢，请求头中的 Accept-Encoding 来标识对压缩的支持。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617142818197.png#pic_center)
&emsp;&emsp;启用 gzip 同时需要客户端和服务端的支持，如果客户端支持 gzip 的解析，那么只要服务端能够返回 gzip 的文件就可以启用 gzip 了,我们可以通过 Nginx 的配置来让服务端支持 gzip 。下面的 respone 中 content-encoding:gzip ，指服务端开启了 gzip 的压缩方式。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617142829912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;在 /etc/nginx/conf.d/ 文件夹中新建配置文件 gzip.conf ：  

```xml
# # 默认off，是否开启gzip
gzip on;
# 要采用 gzip 压缩的 MIME 文件类型，其中 text/html 被系统强制启用；
gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;

# ---- 以上两个参数开启就可以支持Gzip压缩了 ---- #

# 默认 off，该模块启用后，Nginx 首先检查是否存在请求静态文件的 gz 结尾的文件，如果有则直接返回该 .gz 文件内容；
gzip_static on;

# 默认 off，nginx做为反向代理时启用，用于设置启用或禁用从代理服务器上收到相应内容 gzip 压缩；
gzip_proxied any;

# 用于在响应消息头中添加 Vary：Accept-Encoding，使代理服务器根据请求头中的 Accept-Encoding 识别是否启用 gzip 压缩；
gzip_vary on;

# gzip 压缩比，压缩级别是 1-9，1 压缩级别最低，9 最高，级别越高压缩率越大，压缩时间越长，建议 4-6；
gzip_comp_level 6;

# 获取多少内存用于缓存压缩结果，16 8k 表示以 8k*16 为单位获得；
gzip_buffers 16 8k;

# 允许压缩的页面最小字节数，页面字节数从header头中的 Content-Length 中进行获取。默认值是 0，不管页面多大都压缩。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大；
# gzip_min_length 1k;

# 默认 1.1，启用 gzip 所需的 HTTP 最低版本；
gzip_http_version 1.1;
```
&emsp;&emsp;其实也可以通过前端构建工具例如 webpack 、rollup 等在打生产包时就做好 Gzip 压缩，然后放到 Nginx 服务器中，这样可以减少服务器的开销，加快访问速度。  
&emsp;&emsp;关于 Nginx 的实际应用就学习到这里，相信通过掌握了 Nginx 核心配置以及实战配置，之后再遇到什么需求，我们也能轻松应对。接下来，让我们再深入一点学习下 Nginx 的架构。  
# Nginx架构
## 进程结构
&emsp;&emsp;多进程结构 Nginx 的进程模型图：  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617143743753.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
&emsp;&emsp;多进程中的 Nginx 进程架构如下图所示，会有一个父进程（ Master Process ），它会有很多子进程（ Child Processes ）。  

 - Master Process 用来管理子进程的，其本身并不真正处理用户请求
 - 某个子进程 down 掉的话，它会向 Master进程发送一条消息，表明自己不可用了，此时 Master 进程会去新起一个子进程。 
 - 某个配置文件被修改了 Master 进程会去通知work 进程获取新的配置信息，这也就是我们所说的热部署。 
 - 子进程间是通过共享内存的方式进行通信的。  

## 配置文件重载原理
&emsp;&emsp;reload 重载配置文件的流程：  
1. 向 master 进程发送 HUP 信号（ reload 命令）；
2. master 进程检查配置语法是否正确；
3. master 进程打开监听端口；
4. master 进程使用新的配置文件启动新的 worker 子进程；
5. master 进程向老的 worker 子进程发送 QUIT 信号；
6. 老的 worker 进程关闭监听句柄，处理完当前连接后关闭进程；
7. 整个过程 Nginx 始终处于平稳运行中，实现了平滑升级，用户无感知；

## Nginx 模块化管理机制
&emsp;&emsp;Nginx 的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。Nginx 的模块是互相独立的,低耦合高内聚。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210617144400838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTYzMjk2,size_16,color_FFFFFF,t_70#pic_center)
